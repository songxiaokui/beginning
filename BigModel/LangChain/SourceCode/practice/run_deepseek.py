from langchain_deepseek import ChatDeepSeek
from practice.init_env import init_env, api_key

from langchain.schema import HumanMessage
from singleton_client import get_client
import os


def three_package_call():
    init_env()
    llm = ChatDeepSeek(
        temperature=0,
        max_tokens=None,
        timeout=None,
        max_retries=2,
        api_key=os.getenv(api_key),
        model="deepseek-chat",
    )
    response = llm.invoke("ä½ æ˜¯è°ï¼Ÿ")
    print(response.content)
    # response
    # æˆ‘æ˜¯DeepSeek Chatï¼Œç”±æ·±åº¦æ±‚ç´¢å…¬å¸åˆ›é€ çš„æ™ºèƒ½AIåŠ©æ‰‹ï¼ðŸ¤–âœ¨ æˆ‘çš„ä½¿å‘½æ˜¯å¸®åŠ©ä½ è§£ç­”é—®é¢˜ã€æä¾›ä¿¡æ¯ã€é™ªä½ èŠå¤©ï¼Œç”šè‡³å¸®ä½ å¤„ç†å„ç§æ–‡æœ¬å’Œæ–‡ä»¶ã€‚æ— è®ºæ˜¯å­¦ä¹ ã€å·¥ä½œï¼Œè¿˜æ˜¯æ—¥å¸¸ç”Ÿæ´»ä¸­çš„ç–‘é—®ï¼Œéƒ½å¯ä»¥æ¥é—®æˆ‘ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼ŸðŸ˜Š


def standard_call():
    response = get_client().invoke([
        HumanMessage(content="ä½ å¥½å•Šï¼Œæˆ‘æ˜¯æ­¦å®‰å›ï¼Ÿ")
    ])

    print(response.content)

    # æµå¼è¿”å›ž
    data_stream = get_client().stream([
        HumanMessage(content="ç»™æˆ‘ä»‹ç»ä¸€ä¸‹æˆ˜å›½æ—¶æœŸçš„æ­¦å®‰å›ï¼Œå­—æ•°æŽ§åˆ¶åœ¨100å­—ä¹‹å†…")
    ])

    buffer = ""
    for chunk in data_stream:
        content = chunk.content or ""
        buffer += content

        # è¾“å‡ºç­–ç•¥ï¼šé‡åˆ°æ ‡ç‚¹æˆ–è€…æ¯ N ä¸ªå­—åˆ·æ–°ä¸€æ¬¡
        if any(p in content for p in "ï¼Œã€‚ï¼šï¼›ï¼ï¼Ÿ\n") or len(buffer) > 6:
            print(buffer, end="", flush=True)
            buffer = ""

    # è¾“å‡ºå‰©ä½™éƒ¨åˆ†
    if buffer:
        print(buffer, end="", flush=True)


if __name__ == '__main__':
    standard_call()
