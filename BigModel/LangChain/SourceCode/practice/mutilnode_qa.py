"""
å¤šè·¯å¾„æ‰§è¡Œæ™ºèƒ½ä½“

"""
from typing import TypedDict
from langchain.schema import BaseMessage, AIMessage, HumanMessage
from langgraph.graph import START, StateGraph
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
import asyncio
from  singleton_client import get_client


class MutilAgentState(TypedDict):
    messages: list[BaseMessage]
    qa_response: str  # QA
    emotion_response: str  # æƒ…æ„Ÿ


async def qa_model(state: MutilAgentState):
    # ä½¿ç”¨æç¤ºè¯å·¥ç¨‹
    prompt = await new_knowledge_prompt_message().ainvoke(state)

    response = await get_client().ainvoke(prompt)
    return {"qa_response": response.content}


async def emotion_model(state: MutilAgentState):
    # ä½¿ç”¨æç¤ºè¯å·¥ç¨‹
    prompt = await new_emotion_prompt_message().ainvoke(state)

    response = await get_client().ainvoke(prompt)
    return {"emotion_response": response.content}


def merge_results(state: MutilAgentState):
    reply = f"""ğŸ§  ç™¾åº¦ç™¾ç§‘å›å¤ï¼š{state['qa_response']} \nğŸ˜Š æƒ…æ„Ÿåˆ†æï¼š{state['emotion_response']}"""
    return {
        "messages": state["messages"] + [AIMessage(content=reply)]
    }


def new_emotion_prompt_message() -> ChatPromptTemplate:
    return ChatPromptTemplate.from_messages(
        [
            ("system",
             "ä½ ç°åœ¨æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„æƒ…æ„Ÿå¤§å¸ˆï¼Œåªå¯ä»¥çµæ´»çš„å¤„ç†ç”¨æˆ·é—®é¢˜ä¸­åªå…³äºæƒ…æ„Ÿçš„éƒ¨åˆ†è¯é¢˜ï¼Œé™¤äº†æƒ…æ„Ÿè¯é¢˜ï¼Œä½ å•¥ä¹Ÿå¤„ç†ä¸äº†ï¼Œä¹Ÿä¸è¦å»å¤„ç†éæƒ…æ„Ÿè¯é¢˜"),
            MessagesPlaceholder(variable_name="messages"),
        ]
    )


def new_knowledge_prompt_message() -> ChatPromptTemplate:
    return ChatPromptTemplate.from_messages(
        [
            ("system",
             "ä½ ç°åœ¨æ˜¯ç™¾ç§‘å…¨ä¹¦ï¼Œä¸è¦å»å¤„ç†äººç±»æƒ…æ„Ÿé—®é¢˜ï¼Œè¿™é‡Œæ°´å¤ªæ·±ï¼Œå°è€å¼Ÿä½ æŠŠæ¡ä¸ä½ï¼Œä½ å°±è€è€å®å®å¤„ç†å†å²ã€å“²å­¦ã€ä»¥åŠéæƒ…æ„Ÿçš„æ‰€æœ‰é—®é¢˜ï¼Œè®°ä½ï¼Œä½ ä¸æ“…é•¿æƒ…æ„Ÿé—®é¢˜ï¼Œä½ ä¸è¦å›å¤å…³äºæƒ…æ„Ÿçš„é—®é¢˜"),
            MessagesPlaceholder(variable_name="messages"),
        ]
    )


def new_mutil_node_app():
    # é€šè¿‡nodeå®ç°å¤šä¸ªagentè°ƒç”¨
    workflow = StateGraph(state_schema=MutilAgentState)
    workflow.add_node("qa_model", qa_model)  # æ›´æ¢ä¸ºå…¶ä»–çš„æ™ºèƒ½ä½“
    workflow.add_node("emo_model", emotion_model)  # æ›´æ¢ä¸ºå…¶ä»–çš„æ™ºèƒ½ä½“
    workflow.add_node("merge_model", merge_results)

    workflow.add_edge(START, "qa_model")
    workflow.add_edge(START, "emo_model")
    workflow.add_edge("qa_model", "merge_model")
    workflow.add_edge("emo_model", "merge_model")

    return workflow.compile(checkpointer=MemorySaver())


async def run():
    state = {
        "messages": [HumanMessage("æˆ‘ä»Šå¤©å¾ˆéƒé—·ï¼ŒåŒæ—¶æƒ³çŸ¥é“ç§¦å§‹çš‡æ˜¯è°")]
    }
    app = new_mutil_node_app()
    output = await app.ainvoke(state, config={"configurable": {"thread_id": "multi_001"}})
    print(output["messages"][-1].content)


if __name__ == '__main__':
    asyncio.run(run())
