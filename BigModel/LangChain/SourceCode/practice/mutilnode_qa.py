"""
å¤šè·¯å¾„æ‰§è¡Œæ™ºèƒ½ä½“

"""
from typing import TypedDict
from langchain.schema import BaseMessage, AIMessage, HumanMessage
from langgraph.graph import START, StateGraph
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
import asyncio
from singleton_client import get_client


class MutilAgentState(TypedDict):
    messages: list[BaseMessage]
    qa_response: str  # QA
    emotion_response: str  # æƒ…æ„Ÿ
    language: str


async def qa_model(state: MutilAgentState):
    # ä½¿ç”¨æç¤ºè¯å·¥ç¨‹
    prompt = await new_knowledge_prompt_message().ainvoke(state)

    response = await get_client().ainvoke(prompt)
    return {"qa_response": response.content}


async def emotion_model(state: MutilAgentState):
    # ä½¿ç”¨æç¤ºè¯å·¥ç¨‹
    prompt = await new_emotion_prompt_message().ainvoke(state)

    response = await get_client().ainvoke(prompt)
    return {"emotion_response": response.content}


def merge_results(state: MutilAgentState):
    reply = f"""ğŸ§  ç™¾åº¦ç™¾ç§‘å›å¤ï¼š{state['qa_response']} \nğŸ˜Š æƒ…æ„Ÿåˆ†æï¼š{state['emotion_response']}"""
    return {
        "messages": state["messages"] + [AIMessage(content=reply)]
    }


def new_emotion_prompt_message() -> ChatPromptTemplate:
    return ChatPromptTemplate.from_messages(
        [
            ("system",
             "ä½ ç°åœ¨æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„æƒ…æ„Ÿå¤§å¸ˆï¼Œåªå¯ä»¥çµæ´»çš„å¤„ç†ç”¨æˆ·é—®é¢˜ä¸­åªå…³äºæƒ…æ„Ÿçš„éƒ¨åˆ†è¯é¢˜ï¼Œé™¤äº†æƒ…æ„Ÿè¯é¢˜ï¼Œä½ å•¥ä¹Ÿå¤„ç†ä¸äº†ï¼Œä¹Ÿä¸è¦å»å¤„ç†éæƒ…æ„Ÿè¯é¢˜, è¯·ä½¿ç”¨è¯­è¨€ {language} è¿›è¡Œå›å¤"),
            MessagesPlaceholder(variable_name="messages"),
        ]
    )


def new_knowledge_prompt_message() -> ChatPromptTemplate:
    return ChatPromptTemplate.from_messages(
        [
            ("system",
             "ä½ ç°åœ¨æ˜¯ç™¾ç§‘å…¨ä¹¦ï¼Œä¸è¦å»å¤„ç†äººç±»æƒ…æ„Ÿé—®é¢˜ï¼Œè¿™é‡Œæ°´å¤ªæ·±ï¼Œå°è€å¼Ÿä½ æŠŠæ¡ä¸ä½ï¼Œä½ å°±è€è€å®å®å¤„ç†å†å²ã€å“²å­¦ã€ä»¥åŠéæƒ…æ„Ÿçš„æ‰€æœ‰é—®é¢˜ï¼Œè®°ä½ï¼Œä½ ä¸æ“…é•¿æƒ…æ„Ÿé—®é¢˜ï¼Œä½ ä¸è¦å›å¤å…³äºæƒ…æ„Ÿçš„é—®é¢˜ï¼Œè¯·ä½¿ç”¨è¯­è¨€ {language} è¿›è¡Œå›å¤"),
            MessagesPlaceholder(variable_name="messages"),
        ]
    )


def new_mutil_node_app():
    # é€šè¿‡nodeå®ç°å¤šä¸ªagentè°ƒç”¨
    workflow = StateGraph(state_schema=MutilAgentState)
    workflow.add_node("qa_model", qa_model)  # æ›´æ¢ä¸ºå…¶ä»–çš„æ™ºèƒ½ä½“
    workflow.add_node("emo_model", emotion_model)  # æ›´æ¢ä¸ºå…¶ä»–çš„æ™ºèƒ½ä½“
    workflow.add_node("merge_model", merge_results)

    workflow.add_edge(START, "qa_model")
    workflow.add_edge(START, "emo_model")
    workflow.add_edge("qa_model", "merge_model")
    workflow.add_edge("emo_model", "merge_model")

    return workflow.compile(checkpointer=MemorySaver())


async def run():
    state = {
        "messages": [HumanMessage("æ­å·å¯Œé˜³åœºå£è€ƒé©¾ç…§ï¼Œå‘¨æœ«çš„è¯å’Œå·¥ä½œæ—¥æ¯”ï¼Œå•¥æ—¶å€™äººå¤šï¼Œå•¥æ—¶å€™äººå°‘ï¼Œé¡ºä¾¿åˆ†æä¸€ä¸ªï¼Œå‘¨å…­å‘¨æ—¥çš„é€šè¿‡ç‡ï¼Œç§‘äºŒç§‘ä¸‰ï¼Œæ˜¯å•¥æ—¶å€™å»æœ€å¥½ï¼Œè¿™æ˜¯åˆ†æé—®é¢˜ï¼Œæƒ…æ„Ÿä¸è¦å›å¤äº†")],
        "language": "English",
    }
    app = new_mutil_node_app()
    print("ç”¨æˆ·æå‡ºçš„é—®é¢˜: ", state["messages"][-1].content)
    output = await app.ainvoke(state, config={"configurable": {"thread_id": "multi_001"}})
    print(output["messages"][-1].content)


if __name__ == '__main__':
    asyncio.run(run())
